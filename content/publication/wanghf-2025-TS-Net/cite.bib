@article{https://doi.org/10.1002/ima.70064,
author = {Wang, HuiFang and Liu, YaTong and Ye, Jiongyao and Yang, Dawei and Zhu, Yu},
title = {TS-Net: Trans-Scale Network for Medical Image Segmentation},
journal = {International Journal of Imaging Systems and Technology},
volume = {35},
number = {2},
pages = {e70064},
keywords = {convolution modulation, deep supervision, edge loss, feature complementarity, medical image segmentation},
doi = {https://doi.org/10.1002/ima.70064},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ima.70064},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ima.70064},
note = {e70064 IMA-24-1256.R3},
abstract = {ABSTRACT Accurate medical image segmentation is crucial for clinical diagnosis and disease treatment. However, there are still great challenges for most existing methods to extract accurate features from medical images because of blurred boundaries and various appearances. To overcome the above limitations, we propose a novel medical image segmentation network named TS-Net that effectively combines the advantages of CNN and Transformer to enhance the feature extraction ability. Specifically, we design a Multi-scale Convolution Modulation (MCM) module to simplify the self-attention mechanism through a convolution modulation strategy that incorporates multi-scale large-kernel convolution into depth-separable convolution, effectively extracting the multi-scale global features and local features. Besides, we adopt the concept of feature complementarity to facilitate the interaction between high-level semantic features and low-level spatial features through the designed Scale Inter-active Attention (SIA) module. The proposed method is evaluated on four different types of medical image segmentation datasets, and the experimental results show its competence with other state-of-the-art methods. The method achieves an average Dice Similarity Coefficient (DSC) of 90.79\% ± 1.01\% on the public NIH dataset for pancreas segmentation, 76.62\% ± 4.34\% on the public MSD dataset for pancreatic cancer segmentation, 80.70\% ± 6.40\% on the private PROMM (Prostate Multi-parametric MRI) dataset for prostate cancer segmentation, and 91.42\% ± 0.55\% on the public Kvasir-SEG dataset for polyp segmentation. The experimental results across the four different segmentation tasks for medical images demonstrate the effectiveness of the Trans-Scale network.},
year = {2025}
}

